---
layout: post
title: Input. System. Output (A paradigm for life)
---
I came across an article online that claimed a piece of analysis failed because of ‘bad’ data. 

It reminded me of a phrase I used to hear on the trading floor – “US non-farm payrolls beat estimates”.

Hm, can data be inherently good or bad? The state of data is only that they exist and are held as the truth because they exist. Therefore, there must be another reason to explain the system’s unexpected performance.

Input -> System -> Output 

Applying this paradigm to a machine learning/data science project might give something like the following 4 steps.

Source datasets – move datasets from there to here – do something useful with data – show something useful to the world

Putting my paranoid/former trader cap on, 4 steps mean 4 modes of failure. 

For the rest of this blog, I shall pay close attention to mode 2. Otherwise labelled as DevOps, data architecture, data engineering. I never know which one to use so I’ll stick with ‘move datasets from there to here’.

The aim of this blog is to challenge myself and hopefully the reader to think about big data systems at a layer of abstraction that remains invariant in time.

Learn to fish and you’ll never be hungry, or something like that.

Stick around and you can expect to explore:
•	Database principles
•	Types of failure
•	Lambda architecture
•	Where today’s tools fit in
